{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10b041e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parseCSV(idx, records):\n",
    "    for row in csv.reader(records):\n",
    "        direction = 0\n",
    "        bus = row[7].split('_')[2]\n",
    "        tripid = row[7].split('_')[1].split('-')[2]\n",
    "        start = int(row[0].split('T')[1].split(':')[0])\n",
    "        minute = int(row[0].split('T')[1].split(':')[1])\n",
    "        t = datetime.strptime(row[0], '%Y-%m-%dT%H:%M:%SZ')  \n",
    "        date = t.strftime('%Y-%m-%d')\n",
    "        tm = t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        unique_key = str(date) + str(bus) + str(tripid)\n",
    "        \n",
    "        # Create bus direction\n",
    "        # Achilles changes - changed the values for the bearings and switched directions for Q48\n",
    "        \n",
    "        if bus == 'BX1':\n",
    "            if float(row[4]) < 200:\n",
    "                direction = 1\n",
    "            else:\n",
    "                direction = 2\n",
    "        elif bus == 'BX6':\n",
    "            if float(row[4]) < 110:\n",
    "                direction = 1\n",
    "            else:\n",
    "                direction = 2\n",
    "        elif bus == 'BX13':\n",
    "            if 70 <= float(row[4]) < 150:\n",
    "                direction = 1\n",
    "            else:\n",
    "                direction = 2\n",
    "        elif bus == 'Q48':\n",
    "            if 100 <= float(row[4]) < 150:\n",
    "                direction = 2\n",
    "            else:\n",
    "                direction = 1 \n",
    "                \n",
    "        if minute < 15:\n",
    "            interval = str(start) + str(':00-') + str(start) + str(':15')\n",
    "        elif 15 <= minute < 30:\n",
    "            interval = str(start) + str(':15-') + str(start) + str(':30')\n",
    "        elif 30 <= minute < 45:\n",
    "            interval = str(start) + str(':30-') + str(start) + str(':45')\n",
    "        elif 45 <= minute < 60:\n",
    "            interval = str(start) + str(':45-') + str(start+1) + str(':00')\n",
    "\n",
    "        yield unique_key, tm, bus, tripid, direction, interval\n",
    "\n",
    "## Source data file. \n",
    "# path = '/Users/JordanVani/Documents/NYU/BDM/nyc-bus-delay-event/Data/BDM_BusData.csv'\n",
    "path = '/Users/ianstuart/Google Drive/CUSP Courses/Big Data/Project/nyc-bus-delay-event/Data/output.csv'\n",
    "\n",
    "## Parse datafile to RDD.\n",
    "data = sc.textFile(path).mapPartitionsWithIndex(parseCSV)\n",
    "\n",
    "## For each unique bus line, calculate route start time.\n",
    "min_by_group = (data\n",
    "                .map(lambda x: (x[0], x[0:6]))\n",
    "                .reduceByKey(lambda x1, x2: min(x1, x2, key=lambda x: x[1]))\n",
    "                .values()\n",
    "                .map(lambda x: (x[0], (x[1:6]))))\n",
    "\n",
    "## For each unique bus line, calculate route end time.\n",
    "max_by_group = (data\n",
    "                .map(lambda x: (x[0], x[0:2]))\n",
    "                .reduceByKey(lambda x1, x2: max(x1, x2, key=lambda x: x[1]))\n",
    "                .values())\n",
    "\n",
    "## Join start and stop times.\n",
    "rdd = min_by_group.join(max_by_group)\n",
    "rdd = rdd.flatMap(lambda x: [[x[0], x[1][0][0], x[1][1], x[1][0][1],\n",
    "                              x[1][0][2], x[1][0][4]]])\n",
    "\n",
    "# Calculate duration of bus.\n",
    "time_diff = rdd.toDF(['id', 'start', 'stop', 'bus', 'tripid', 'interval'])\n",
    "time_diff = time_diff.select('id', time_diff['start'].cast('timestamp'),\n",
    "                             time_diff['stop'].cast('timestamp'), 'bus', 'tripid', 'interval')\n",
    "timeDiff = (functions.unix_timestamp('stop', format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "            - functions.unix_timestamp('start', format=\"yyyy-MM-dd HH:mm:ss\"))\n",
    "time_diff = time_diff.withColumn('duration', timeDiff)\n",
    "\n",
    "# Calculate mean direction\n",
    "trip_dir = data.toDF(['id_', 'time', 'bus', 'tripid', 'direction', 'interval'])\n",
    "trip_dir = trip_dir.groupby(\"id_\").agg({'direction': 'avg'})\n",
    "\n",
    "# Join direction back to data.\n",
    "master = time_diff.join(trip_dir, time_diff.id == trip_dir.id_, how='left_outer')\n",
    "master = master.select('id', 'start', 'bus', 'tripid', 'interval', 'duration', \n",
    "                       functions.col('avg(direction)').cast('int').alias('direction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+------+-----------+--------+---------+\n",
      "|                  id|               start| bus|tripid|   interval|duration|direction|\n",
      "+--------------------+--------------------+----+------+-----------+--------+---------+\n",
      "| 2014-08-12BX6040500|2014-08-12 10:50:...| BX6|040500|10:45-11:00|    3516|        1|\n",
      "| 2014-08-12BX6082600|2014-08-12 17:48:...| BX6|082600|17:45-18:00|    3716|        1|\n",
      "|2014-08-12BX13099600|2014-08-12 20:37:...|BX13|099600|20:30-20:45|    3298|        2|\n",
      "|2014-08-12BX13073800|2014-08-12 16:25:...|BX13|073800|16:15-16:30|    2329|        1|\n",
      "|2014-08-12BX13076800|2014-08-12 16:37:...|BX13|076800|16:30-16:45|    3225|        2|\n",
      "+--------------------+--------------------+----+------+-----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_times = (master\n",
    "             .groupby(\"bus\", functions.date_format('start', 'yyyy-MM-dd').alias('date'), \n",
    "                      \"direction\", \"interval\")\n",
    "             .agg({\"duration\": \"avg\", \"id\": \"count\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(rdd_times\n",
    " .sort(functions.col('bus'), functions.col('date'), functions.col('interval'))\n",
    " .show(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in schedule data\n",
    "schedules = sc.textFile('game_schedules/combined_schedules.csv').map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert schedule data to dataframe\n",
    "sched_df = schedules.toDF(['index','Home team','starttime','endtime','startwindow_start', \\\n",
    "                               'startwindow_end','endwindow_start','endwindow_end'])\n",
    "sched_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- Home team: string (nullable = true)\n",
      " |-- starttime: string (nullable = true)\n",
      " |-- endtime: string (nullable = true)\n",
      " |-- startwindow_start: string (nullable = true)\n",
      " |-- startwindow_end: string (nullable = true)\n",
      " |-- endwindow_start: string (nullable = true)\n",
      " |-- endwindow_end: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sched_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- start: timestamp (nullable = true)\n",
      " |-- bus: string (nullable = true)\n",
      " |-- tripid: string (nullable = true)\n",
      " |-- interval: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- direction: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert all time columns to type 'timestamp'\n",
    "for col in sched_df.columns[2:]:\n",
    "    sched_df = sched_df.withColumn(col, sched_df[col].cast('timestamp'))\n",
    "sched_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a 'date' column to use for join with rdd_times\n",
    "sched_df = sched_df.withColumn('date', functions.date_format('starttime', 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join schedule data to bus interval data\n",
    "joined_df = rdd_times.join(sched_df, 'date', 'left')\n",
    "joined_df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop('index', 'Home team', 'starttime', 'endtime')\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, col\n",
    "\n",
    "joined_df = joined_df.withColumn('time', functions.split(joined_df.interval, '-')[0])\n",
    "joined_df = joined_df.withColumn('start', functions.concat(col('date'), lit(' '), \\\n",
    "                                                           col('time')).cast('timestamp'))\n",
    "joined_df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop('time')\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def checkWindows(start, start_start, start_end, end_start, end_end):\n",
    "    if (start >= start_start) & (start <= start_end) | \\\n",
    "            (start >= end_start) & (start <= end_end):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "labelFunc = udf(checkWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_df = joined_df.withColumn('is_game_bus', labelFunc(joined_df.start, \\\n",
    "                                                    joined_df.startwindow_start, \\\n",
    "                                                    joined_df.startwindow_end, \\\n",
    "                                                    joined_df.endwindow_start, \\\n",
    "                                                    joined_df.endwindow_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date=u'2014-08-12', bus=u'BX1', direction=2, interval=u'11:00-11:15', avg(duration)=1352.0, count(id)=1, startwindow_start=datetime.datetime(2014, 8, 12, 17, 40), startwindow_end=datetime.datetime(2014, 8, 12, 19, 40), endwindow_start=datetime.datetime(2014, 8, 12, 21, 36), endwindow_end=datetime.datetime(2014, 8, 12, 23, 36), start=datetime.datetime(2014, 8, 12, 11, 0), is_game_bus=u'0'),\n",
       " Row(date=u'2014-08-12', bus=u'BX1', direction=1, interval=u'9:45-10:00', avg(duration)=3688.0, count(id)=1, startwindow_start=datetime.datetime(2014, 8, 12, 17, 40), startwindow_end=datetime.datetime(2014, 8, 12, 19, 40), endwindow_start=datetime.datetime(2014, 8, 12, 21, 36), endwindow_end=datetime.datetime(2014, 8, 12, 23, 36), start=datetime.datetime(2014, 8, 12, 9, 45), is_game_bus=u'0'),\n",
       " Row(date=u'2014-08-12', bus=u'BX1', direction=1, interval=u'10:45-11:00', avg(duration)=3403.0, count(id)=1, startwindow_start=datetime.datetime(2014, 8, 12, 17, 40), startwindow_end=datetime.datetime(2014, 8, 12, 19, 40), endwindow_start=datetime.datetime(2014, 8, 12, 21, 36), endwindow_end=datetime.datetime(2014, 8, 12, 23, 36), start=datetime.datetime(2014, 8, 12, 10, 45), is_game_bus=u'0'),\n",
       " Row(date=u'2014-08-12', bus=u'BX6', direction=1, interval=u'21:30-21:45', avg(duration)=3100.0, count(id)=5, startwindow_start=datetime.datetime(2014, 8, 12, 17, 40), startwindow_end=datetime.datetime(2014, 8, 12, 19, 40), endwindow_start=datetime.datetime(2014, 8, 12, 21, 36), endwindow_end=datetime.datetime(2014, 8, 12, 23, 36), start=datetime.datetime(2014, 8, 12, 21, 30), is_game_bus=u'0'),\n",
       " Row(date=u'2014-08-12', bus=u'BX1', direction=1, interval=u'11:45-12:00', avg(duration)=3911.5, count(id)=4, startwindow_start=datetime.datetime(2014, 8, 12, 17, 40), startwindow_end=datetime.datetime(2014, 8, 12, 19, 40), endwindow_start=datetime.datetime(2014, 8, 12, 21, 36), endwindow_end=datetime.datetime(2014, 8, 12, 23, 36), start=datetime.datetime(2014, 8, 12, 11, 45), is_game_bus=u'0')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
